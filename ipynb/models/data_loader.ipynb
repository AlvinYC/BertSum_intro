{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import random\n",
    "import torch\n",
    "\n",
    "#from others.logging import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch(object):\n",
    "    def _pad(self, data, pad_id, width=-1):\n",
    "        if (width == -1):\n",
    "            width = max(len(d) for d in data)\n",
    "        rtn_data = [d + [pad_id] * (width - len(d)) for d in data]\n",
    "        return rtn_data\n",
    "\n",
    "    def __init__(self, data=None, device=None,  is_test=False):\n",
    "        \"\"\"Create a Batch from a list of examples.\"\"\"\n",
    "        if data is not None:\n",
    "            self.batch_size = len(data)\n",
    "            pre_src = [x[0] for x in data]\n",
    "            pre_labels = [x[1] for x in data]\n",
    "            pre_segs = [x[2] for x in data]\n",
    "            pre_clss = [x[3] for x in data]\n",
    "\n",
    "            src = torch.tensor(self._pad(pre_src, 0))\n",
    "\n",
    "            labels = torch.tensor(self._pad(pre_labels, 0))\n",
    "            segs = torch.tensor(self._pad(pre_segs, 0))\n",
    "            mask = 1 - (src == 0)\n",
    "\n",
    "            clss = torch.tensor(self._pad(pre_clss, -1))\n",
    "            mask_cls = 1 - (clss == -1)\n",
    "            clss[clss == -1] = 0\n",
    "\n",
    "            setattr(self, 'clss', clss.to(device))\n",
    "            setattr(self, 'mask_cls', mask_cls.to(device))\n",
    "            setattr(self, 'src', src.to(device))\n",
    "            setattr(self, 'labels', labels.to(device))\n",
    "            setattr(self, 'segs', segs.to(device))\n",
    "            setattr(self, 'mask', mask.to(device))\n",
    "\n",
    "            if (is_test):\n",
    "                src_str = [x[-2] for x in data]\n",
    "                setattr(self, 'src_str', src_str)\n",
    "                tgt_str = [x[-1] for x in data]\n",
    "                setattr(self, 'tgt_str', tgt_str)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(data, batch_size):\n",
    "    \"\"\"Yield elements from data in chunks of batch_size.\"\"\"\n",
    "    minibatch, size_so_far = [], 0\n",
    "    for ex in data:\n",
    "        minibatch.append(ex)\n",
    "        size_so_far = simple_batch_size_fn(ex, len(minibatch))\n",
    "        if size_so_far == batch_size:\n",
    "            yield minibatch\n",
    "            minibatch, size_so_far = [], 0\n",
    "        elif size_so_far > batch_size:\n",
    "            yield minibatch[:-1]\n",
    "            minibatch, size_so_far = minibatch[-1:], simple_batch_size_fn(ex, 1)\n",
    "    if minibatch:\n",
    "        yield minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(args, corpus_type, shuffle):\n",
    "    assert corpus_type in [\"train\", \"valid\", \"test\"]\n",
    "\n",
    "    def _lazy_dataset_loader(pt_file, corpus_type):\n",
    "        dataset = torch.load(pt_file)\n",
    "        logger.info('Loading %s dataset from %s, number of examples: %d' %\n",
    "                    (corpus_type, pt_file, len(dataset)))\n",
    "        return dataset\n",
    "\n",
    "    # Sort the glob output by file name (by increasing indexes).\n",
    "    pts = sorted(glob.glob(args.bert_data_path + '.' + corpus_type + '.[0-9]*.pt'))\n",
    "    if pts:\n",
    "        if (shuffle):\n",
    "            random.shuffle(pts)\n",
    "\n",
    "        for pt in pts:\n",
    "            yield _lazy_dataset_loader(pt, corpus_type)\n",
    "    else:\n",
    "        # Only one inputters.*Dataset, simple!\n",
    "        pt = args.bert_data_path + '.' + corpus_type + '.pt'\n",
    "        yield _lazy_dataset_loader(pt, corpus_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_batch_size_fn(new, count):\n",
    "    src, labels = new[0], new[1]\n",
    "    global max_n_sents, max_n_tokens, max_size\n",
    "    if count == 1:\n",
    "        max_size = 0\n",
    "        max_n_sents=0\n",
    "        max_n_tokens=0\n",
    "    max_n_sents = max(max_n_sents, len(src))\n",
    "    max_size = max(max_size, max_n_sents)\n",
    "    src_elements = count * max_size\n",
    "    return src_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader(object):\n",
    "    def __init__(self, args, datasets,  batch_size,\n",
    "                 device, shuffle, is_test):\n",
    "        self.args = args\n",
    "        self.datasets = datasets\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.shuffle = shuffle\n",
    "        self.is_test = is_test\n",
    "        self.cur_iter = self._next_dataset_iterator(datasets)\n",
    "\n",
    "        assert self.cur_iter is not None\n",
    "\n",
    "    def __iter__(self):\n",
    "        dataset_iter = (d for d in self.datasets)\n",
    "        while self.cur_iter is not None:\n",
    "            for batch in self.cur_iter:\n",
    "                yield batch\n",
    "            self.cur_iter = self._next_dataset_iterator(dataset_iter)\n",
    "\n",
    "\n",
    "    def _next_dataset_iterator(self, dataset_iter):\n",
    "        try:\n",
    "            # Drop the current dataset for decreasing memory\n",
    "            if hasattr(self, \"cur_dataset\"):\n",
    "                self.cur_dataset = None\n",
    "                gc.collect()\n",
    "                del self.cur_dataset\n",
    "                gc.collect()\n",
    "\n",
    "            self.cur_dataset = next(dataset_iter)\n",
    "        except StopIteration:\n",
    "            return None\n",
    "\n",
    "        return DataIterator(args = self.args,\n",
    "            dataset=self.cur_dataset,  batch_size=self.batch_size,\n",
    "            device=self.device, shuffle=self.shuffle, is_test=self.is_test)\n",
    "\n",
    "\n",
    "class DataIterator(object):\n",
    "    def __init__(self, args, dataset,  batch_size,  device=None, is_test=False,\n",
    "                 shuffle=True):\n",
    "        self.args = args\n",
    "        self.batch_size, self.is_test, self.dataset = batch_size, is_test, dataset\n",
    "        self.iterations = 0\n",
    "        self.device = device\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        self.sort_key = lambda x: len(x[1])\n",
    "\n",
    "        self._iterations_this_epoch = 0\n",
    "\n",
    "    def data(self):\n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.dataset)\n",
    "        xs = self.dataset\n",
    "        return xs\n",
    "\n",
    "\n",
    "    def preprocess(self, ex, is_test):\n",
    "        src = ex['src']\n",
    "        if('labels' in ex):\n",
    "            labels = ex['labels']\n",
    "        else:\n",
    "            labels = ex['src_sent_labels']\n",
    "\n",
    "        segs = ex['segs']\n",
    "        if(not self.args.use_interval):\n",
    "            segs=[0]*len(segs)\n",
    "        clss = ex['clss']\n",
    "        src_txt = ex['src_txt']\n",
    "        tgt_txt = ex['tgt_txt']\n",
    "\n",
    "        if(is_test):\n",
    "            return src,labels,segs, clss, src_txt, tgt_txt\n",
    "        else:\n",
    "            return src,labels,segs, clss\n",
    "\n",
    "    def batch_buffer(self, data, batch_size):\n",
    "        minibatch, size_so_far = [], 0\n",
    "        for ex in data:\n",
    "            if(len(ex['src'])==0):\n",
    "                continue\n",
    "            ex = self.preprocess(ex, self.is_test)\n",
    "            if(ex is None):\n",
    "                continue\n",
    "            minibatch.append(ex)\n",
    "            size_so_far = simple_batch_size_fn(ex, len(minibatch))\n",
    "            if size_so_far == batch_size:\n",
    "                yield minibatch\n",
    "                minibatch, size_so_far = [], 0\n",
    "            elif size_so_far > batch_size:\n",
    "                yield minibatch[:-1]\n",
    "                minibatch, size_so_far = minibatch[-1:], simple_batch_size_fn(ex, 1)\n",
    "        if minibatch:\n",
    "            yield minibatch\n",
    "\n",
    "    def create_batches(self):\n",
    "        \"\"\" Create batches \"\"\"\n",
    "        data = self.data()\n",
    "        for buffer in self.batch_buffer(data, self.batch_size * 50):\n",
    "\n",
    "            p_batch = sorted(buffer, key=lambda x: lï¿¼en(x[3]))\n",
    "            p_batch = batch(p_batch, self.batch_size)\n",
    "\n",
    "            p_batch = list(p_batch)\n",
    "            if (self.shuffle):\n",
    "                random.shuffle(p_batch)\n",
    "            for b in p_batch:\n",
    "                yield b\n",
    "\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            self.batches = self.create_batches()\n",
    "            for idx, minibatch in enumerate(self.batches):\n",
    "                # fast-forward if loaded from state\n",
    "                if self._iterations_this_epoch > idx:\n",
    "                    continue\n",
    "                self.iterations += 1\n",
    "                self._iterations_this_epoch += 1\n",
    "                batch = Batch(minibatch, self.device, self.is_test)\n",
    "\n",
    "                yield batch\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch(object):\n",
    "    def _pad(self, data, pad_id, width=-1):\n",
    "        return rtn_data\n",
    "\n",
    "    def __init__(self, data=None, device=None,  is_test=False):\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(data, batch_size):\n",
    "    yield minibatch    \n",
    "\n",
    "def load_dataset(args, corpus_type, shuffle):\n",
    "    yield _lazy_dataset_loader(pt, corpus_type)   \n",
    "\n",
    "def simple_batch_size_fn(new, count):\n",
    "    return src_elements        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader(object):\n",
    "    def __init__(self, args, datasets,  batch_size, device, shuffle, is_test):\n",
    "        assert self.cur_iter is not None\n",
    "\n",
    "    def __iter__(self):\n",
    "        yield batch\n",
    "\n",
    "    def _next_dataset_iterator(self, dataset_iter):\n",
    "        return DataIterator(args = self.args,  dataset=self.cur_dataset,  batch_size=self.batch_size,\n",
    "            device=self.device, shuffle=self.shuffle, is_test=self.is_test)\n",
    "    \n",
    "class DataIterator(object):\n",
    "    def __init__(self, args, dataset,  batch_size,  device=None, is_test=False, shuffle=True):\n",
    "\n",
    "    def data(self):\n",
    "        return xs\n",
    "\n",
    "    def preprocess(self, ex, is_test):\n",
    "        return src,labels,segs, clss\n",
    "\n",
    "    def batch_buffer(self, data, batch_size):\n",
    "        yield minibatch\n",
    "\n",
    "    def create_batches(self):\n",
    "        yield b\n",
    "\n",
    "    def __iter__(self):\n",
    "        batch = Batch(minibatch, self.device, self.is_test)\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/alvin/workspace/BertSum/bert_data/cnndm.train.0.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.1.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.10.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.100.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.101.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.102.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.103.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.104.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.105.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.106.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.107.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.108.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.109.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.11.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.110.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.111.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.112.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.113.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.114.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.115.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.116.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.117.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.118.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.119.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.12.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.120.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.121.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.122.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.123.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.124.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.125.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.126.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.127.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.128.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.129.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.13.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.130.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.131.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.132.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.133.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.134.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.135.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.136.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.137.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.138.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.139.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.14.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.140.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.141.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.142.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.143.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.15.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.16.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.17.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.18.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.19.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.2.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.20.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.21.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.22.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.23.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.24.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.25.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.26.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.27.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.28.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.29.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.3.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.30.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.31.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.32.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.33.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.34.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.35.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.36.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.37.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.38.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.39.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.4.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.40.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.41.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.42.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.43.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.44.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.45.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.46.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.47.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.48.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.49.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.5.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.50.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.51.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.52.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.53.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.54.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.55.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.56.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.57.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.58.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.59.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.6.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.60.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.61.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.62.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.63.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.64.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.65.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.66.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.67.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.68.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.69.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.7.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.70.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.71.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.72.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.73.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.74.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.75.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.76.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.77.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.78.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.79.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.8.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.80.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.81.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.82.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.83.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.84.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.85.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.86.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.87.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.88.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.89.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.9.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.90.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.91.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.92.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.93.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.94.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.95.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.96.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.97.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.98.bert.pt',\n",
       " '/home/alvin/workspace/BertSum/bert_data/cnndm.train.99.bert.pt']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_type = 'train'\n",
    "args.bert_data_path = '/home/alvin/workspace/BertSum/bert_data/cnndm'\n",
    "pts = sorted(glob.glob(args.bert_data_path + '.' + corpus_type + '.[0-9]*.pt'))\n",
    "args.bert_data_path\n",
    "pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "/home/alvin/workspace/BertSum/bert_data/cnndm.train.132.bert.pt\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(pts)\n",
    "print(type(pts))\n",
    "print(pts[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.load(pts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of dataset = <class 'list'>\n",
      "type of dataset[0] = <class 'dict'>\n",
      "keys of dataset[0] = dict_keys(['src', 'labels', 'segs', 'clss', 'src_txt', 'tgt_txt'])\n"
     ]
    }
   ],
   "source": [
    "print('type of dataset = ' + str(type(dataset)))\n",
    "print('type of dataset[0] = ' + str(type(dataset[0])))\n",
    "print('keys of dataset[0] = ' + str(dataset[0].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[0]['src_txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------- src\n",
      " [101, 1996, 1057, 1012, 1055, 1012, 3187, 1997, 2740, 2758, 2045, 2024, 3497, 1036, 2062, 3572, 1005, 1997, 1041, 24290, 2006, 2149, 5800, 1998, 2008, 3199, 11326, 2013, 6712, 3032, 2003, 6827, 1999, 10723, 1996, 3659, 1012, 102, 101, 1036, 2057, 2018, 2028, 2553, 1998, 1045, 2228, 2045, 2089, 2022, 2060, 3572, 1010, 1998, 1045, 2228, 2057, 2031, 2000, 6807, 2008, 2004, 1037, 3842, 1010, 1005, 20934, 2099, 4381, 2056, 2012, 1037, 2865, 6350, 2651, 1012, 102, 101, 20934, 2099, 4381, 4208, 2006, 3199, 11326, 1998, 2056, 2348, 2009, 2001, 2025, 2531, 3867, 4621, 2016, 2018, 7023, 1999, 1996, 3653, 3540, 13700, 1012, 102, 101, 2062, 3497, 2062, 3572, 1024, 2740, 1998, 2529, 2578, 3187, 13378, 20934, 2099, 4381, 2038, 2056, 2008, 3572, 1997, 1041, 24290, 2089, 2525, 2022, 1999, 1996, 2142, 2163, 1998, 2008, 29174, 1997, 1996, 4295, 2003, 6827, 2005, 9740, 102, 101, 26629, 2472, 1024, 7458, 3604, 2000, 1998, 2013, 2225, 3088, 2035, 2362, 2097, 4652, 29174, 1997, 1996, 4295, 2306, 3088, 1998, 2097, 2059, 3659, 2000, 1996, 2142, 2163, 1998, 3033, 1997, 2885, 102, 101, 1036, 1996, 2087, 2590, 2173, 2007, 7634, 2000, 2635, 2729, 1997, 11326, 2003, 2941, 2012, 1996, 2391, 1997, 6712, 1010, 1005, 2016, 2056, 1010, 2988, 1996, 2899, 19684, 1012, 102, 101, 1036, 1998, 2008, 1005, 1055, 2042, 1999, 2173, 2005, 2116, 2706, 1998, 2004, 2057, 2113, 1010, 2057, 2031, 1037, 2553, 1012, 102, 101, 2008, 2553, 13718, 2003, 10181, 1012, 102, 101, 2021, 2005, 2116, 2706, 1010, 2057, 2106, 2025, 2031, 1037, 2553, 2008, 3133, 1996, 2406, 1012, 102, 101, 1036, 1998, 2057, 2113, 2008, 2008, 11326, 2038, 2499, 1999, 1996, 3168, 1997, 3770, 2111, 2031, 2042, 2766, 2013, 1996, 3210, 1999, 1996, 11326, 1998, 3030, 1999, 1996, 2188, 2406, 1012, 102, 101, 1998, 2008, 1005, 1055, 1996, 2087, 2590, 2173, 2000, 2079, 2008, 1012, 1005, 102, 101, 2757, 1024, 2726, 4388, 7343, 1997, 18039, 2003, 1996, 2034, 2158, 2000, 2022, 11441, 2007, 1041, 24290, 2006, 2137, 5800, 1998, 2351, 2006, 9317, 1999, 5759, 1010, 3146, 2073, 2002, 2001, 2108, 5845, 2005, 1996, 9252, 7865, 102, 101, 1996, 2034, 5776, 11441, 2007, 1996, 7865, 2001, 18039, 2078, 2158, 2726, 4388, 7343, 1010, 4413, 1010, 2040, 2351, 2006, 9317, 1012, 102, 101, 2144, 7343, 1005, 1055, 13800, 11616, 1010, 13586, 1999, 2225, 3088, 2031, 21106, 2037, 11326, 16744, 2000, 2191, 2469, 2053, 2028, 2007, 1996, 7865, 3727, 1996, 2406, 1012, 102, 101, 2429, 2000, 1996, 2472, 1997, 1996, 2415, 2005, 4295, 2491, 1998, 9740, 1010, 2852, 1012, 3419, 10424, 7416, 7847, 1010, 7458, 3604, 2000, 1998, 2013, 2225, 3088, 2035, 2362, 2097, 4652, 29174, 1997, 1996, 4295, 2306, 3088, 1998, 2097, 2059, 3659, 2000, 1996, 2142, 2163, 1998, 3033, 1997, 2885, 1012, 102, 101, 2055, 1022, 1010, 2199, 9871, 3667, 2031, 2042, 20888, 2083, 2019, 9499, 2897, 1998, 2031, 2042, 2006, 26629, 4773, 3981, 2869, 1012, 102, 101, 2885, 2097, 2471, 21268, 2156, 2062, 3572, 1997, 1996, 9252, 1041, 24290, 7865, 2306, 2049, 6645, 2021, 1996, 9983, 2003, 2092, 4810, 2000, 2491, 1996, 4295, 1010, 1996, 2088, 2740, 3029, 1005, 1055, 3164, 2472, 102]\n",
      "---------------------------------- label\n",
      " [1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------------- seg\n",
      " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------------- clss\n",
      " [0, 38, 77, 104, 144, 178, 209, 232, 240, 258, 291, 306, 345, 369, 399, 451, 475]\n",
      "---------------------------------- src_txt\n",
      " [\"the u.s. secretary of health says there are likely ` more cases ' of ebola on us soil and that airport screening from departure countries is essential in preventing the spread .\", \"` we had one case and i think there may be other cases , and i think we have to recognize that as a nation , ' burwell said at a media breakfast today .\", 'burwell focused on airport screening and said although it was not 100 percent effective she had confidence in the precaution .', 'more likely more cases : health and human services secretary sylvia burwell has said that cases of ebola may already be in the united states and that containment of the disease is essential for prevention', 'cdc director : stopping travel to and from west africa all together will prevent containment of the disease within africa and will then spread to the united states and parts of europe', \"` the most important place with regard to taking care of screening is actually at the point of departure , ' she said , reported the washington examiner .\", \"` and that 's been in place for many months and as we know , we have a case .\", 'that case sadly is deceased .', 'but for many months , we did not have a case that entered the country .', '` and we know that that screening has worked in the sense of 80 people have been pulled from the lines in the screening and stopped in the home country .', \"and that 's the most important place to do that . '\", 'dead : thomas eric duncan of liberia is the first man to be diagnosed with ebola on american soil and died on wednesday in dallas , texas where he was being treated for the deadly virus', 'the first patient diagnosed with the virus was liberian man thomas eric duncan , 42 , who died on wednesday .', \"since duncan 's tragic diagnosis , airports in west africa have heightened their screening protocols to make sure no one with the virus leaves the country .\", 'according to the director of the center for disease control and prevention , dr. tom freidan , stopping travel to and from west africa all together will prevent containment of the disease within africa and will then spread to the united states and parts of europe .', 'about 8,000 healthcare workers have been communicating through an alert network and have been on cdc webinars .', \"europe will almost inevitably see more cases of the deadly ebola virus within its borders but the continent is well prepared to control the disease , the world health organization 's regional director said on tuesday .\", 'departure screenings : screenings at u.s. airports in departure countries like west africa are essential to containment and identification of the deadly virus', \"speaking to reuters just hours after europe 's first local case of ebola infection was confirmed in a nurse in spain , the who 's european director , zsuzsanna jakab , said further such events were ` unavoidable . '\", 'spanish health officials said four people had been hospitalized to try and stem any further spread of ebola there after the nurse became the first person in the world known to have contracted the virus outside of africa .', \"` such imported cases and similar events as have happened inspain will happen also in the future , most likely , ' jakab told reuters in a telephone interview from her copenhagen office .\", 'spreading : ebola has infected some 7,200 people in west africa , killing more than 3,400 of them in the largest outbreak of the disease in history', \"` it is quite unavoidable ... that such incidents will happen in the future because of the extensive travel both from europe to the affected countries and the other way around . '\", \"several countries in the who 's european region , including france , britain , the netherlands , germany , switzerland , norway and spain , have treated patients repatriated after contracting the disease in west africa , where ebola has been raging through guinea , sierra leone and liberia since march .\", 'ebola has infected some 7,200 people in west africa , killing more than 3,400 of them in the largest outbreak of the disease in history .', 'cases have also been imported into nigeria , senegal and the united states .', 'jakab said that within europe , health workers caring for repatriated ebola patients , as well as their families and close contacts , were most at risk of becoming infected .', \"` but the most important thing ... is that europe is still at low risk and that the western part of the european region particularly is the best prepared in the world to respond to viral hemorrhagic fevers including ebola . '\"]\n",
      "---------------------------------- tgt_txt\n",
      " despite efforts in the united states to stop the spread of the deadly ebola virus , there may be more cases on american soil than already realized<q>travelers leaving west africa may have already brought the virus into the country , says secretary of health and human services sylvia burwell<q>` the most important place with regard to taking care of screening is actually at the point of departure , ' she said<q>the director of the world health organization said that cases of ebola in parts of europe are ` unavoidable '\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------------------- src\\n \"+ str(dataset[0]['src']))\n",
    "print(\"---------------------------------- label\\n \"+ str(dataset[0]['labels']))\n",
    "print(\"---------------------------------- seg\\n \" + str(dataset[0]['segs']))\n",
    "print(\"---------------------------------- clss\\n \" + str(dataset[0]['clss']))\n",
    "print(\"---------------------------------- src_txt\\n \" + str(dataset[0]['src_txt']))\n",
    "print(\"---------------------------------- tgt_txt\\n \" + str(dataset[0]['tgt_txt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
